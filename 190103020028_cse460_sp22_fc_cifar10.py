# -*- coding: utf-8 -*-
"""190103020028_cse460_sp22_fc_cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ETphCnpKhGX3o4cVXQGhahSgHIlsJtiR
"""

# Tensorflow 2.0
# PyTorch

"""### Instruction
1. File->Save a copy in Drive
2. Rename: replace reg_no with your registration no.
3. Put your name

### Task
1. Try changing number of neurons
2. Try chaning number of hidden layers
3. Try changing learning rates
4. Try ... any other things to improve accuracy.

### Name: your name
### Maximum testing accuracy achieved:

### FC on CIFAR 10 Dataset
"""

import tensorflow as tf
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.datasets import cifar10
import numpy as np
import matplotlib.pyplot as plt

# setting class names
class_names=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
(x_train,y_train),(x_test,y_test)=cifar10.load_data()

x_train.shape

y_train.shape

y_train[:5]

x_test.shape

y_test.shape

# x_train[0]







"""### subtract mean"""

#todo

x_train=x_train/255.0
x_train.shape

x_test=x_test/255.0
x_test.shape

# x_train[0]



ri=np.random.randint(x_train.shape[0])
print('ri=', ri)

ri=5
x=x_train[ri]

y_train[ri]

plt.imshow(x)







32*32*3

3072*200+200

model = tf.keras.Sequential()
model.add( Flatten(input_shape=(32, 32, 3) ) )
model.add( Dense(500, activation='relu' ) ) 
model.add( Dense(200, activation='relu' ) ) 
model.add( Dense(150, activation='relu' ) ) 
model.add(Dense(10, activation='softmax'))
model.summary()







#search google to set learning rate.

model.compile(loss="sparse_categorical_crossentropy",  optimizer="Adam", metrics=['accuracy'])
model.optimizer.lr.assign(0.0001)

# hist=model.fit(x_train, y_train, epochs=50)
hist = model.fit(x_train, y_train, validation_split= 0.20, epochs=60)

print('shape:', x_train.shape, y_train.shape)

print(hist.history.keys())

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title("Model Accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend(['train','validation'],loc='upper left')
plt.show()

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title("Model loss")
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend(['train','validation'],loc='upper left')
plt.show()



test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test accuracy: {test_accuracy}")



# xt=x_test[10]
xt=x_test[2311]
plt.imshow(xt)

p=model.predict(xt.reshape(-1, 32,32,3))
print(p)

yhat=np.argmax(p)
yhat

print('predicted:', class_names[yhat])





z=[0.7 ,1.2]

import numpy as np

yh1=np.exp(z[0])/ (np.exp(z[0])+np.exp(z[1]))
yh1

yh2=np.exp(z[1])/ (np.exp(z[0])+np.exp(z[1]))
yh2



